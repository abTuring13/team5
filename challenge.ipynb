{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchpress Hackathon\n",
    "\n",
    "The challenge comes with a Jupyter notebook for your implementation and various utilities.\n",
    "We provide a development set and a validation set you can use to develop your solution.\n",
    "The development set is for testing your code and consists of 300 problems with a varying number of test cases.\n",
    "You are free to use all data provided with a problem, a sample has the following structure:\n",
    "\n",
    "```python\n",
    "{\n",
    "    # Unique identifier for the problem in the APPS dataset.\n",
    "    \"problem_id\": 4424,\n",
    "    # The problem statement\n",
    "    \"question\": \"Given three integers ...\",\n",
    "    # The expected function name and the input/output examples\n",
    "    # representing test cases.\n",
    "    \"input_output\": {\n",
    "        \"fn_name\": \"expression_matter\",\n",
    "        \"inputs\": [ ... ],\n",
    "        \"outputs\": [ ... ]\n",
    "    },\n",
    "    \"url\": \"https://www.codewars.com/kata/5ae62fcf252e66d44d00008e\",\n",
    "    \"difficulty\": \"introductory\",\n",
    "    # The starter code for the problem.\n",
    "    \"starter_code\": \"def expression_matter(a, b, c):\\n\\t\"\n",
    "}\n",
    "```\n",
    "\n",
    "The validation set is consists of 200 problems, and includes an additional key `test_cases` which is used to score your solution with the provided scoring function.\n",
    "\n",
    "```python\n",
    "{\n",
    "    ...\n",
    "    \"test_cases\": {\n",
    "        \"fn_name\": \"expression_matter\",\n",
    "        \"inputs\": [ ... ],\n",
    "        \"outputs\": [ ... ]\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### Loading Problems\n",
    "\n",
    "Use the `load_sample` function to load a problem from the development or validation set.\n",
    "\n",
    "```python\n",
    "from utilities import load_sample\n",
    "\n",
    "problem = load_sample(index=0, dataset_path=\"./data/dev\")\n",
    "```\n",
    "\n",
    "### Generating Code\n",
    "\n",
    "Use the `aleph_alpha_client` to generate code.\n",
    "Make sure your `AA_TOKEN` is set.\n",
    "\n",
    "```python\n",
    "from aleph_alpha_client import Client, CompletionRequest, Prompt\n",
    "\n",
    "client = Client(AA_TOKEN)\n",
    "\n",
    "request = CompletionRequest(\n",
    "    prompt=Prompt.from_text(\"Your prompt.\"),\n",
    "    maximum_tokens=256,\n",
    ")\n",
    "\n",
    "# API reference for the client:\n",
    "# https://aleph-alpha-client.readthedocs.io/en/latest/\n",
    "response = client.complete(request, model=MODEL)\n",
    "```\n",
    "\n",
    "### Running Tests\n",
    "\n",
    "Use the `run_test_cases` function to run the generated code against the test cases.\n",
    "The function returns a dictionary with the test results, including the expected output, the generated output, a boolean indicating whether the test passed and a traceback in case of an error.\n",
    "\n",
    "```python\n",
    "from utilities import run_test_cases\n",
    "\n",
    "test_results = run_test_cases(\n",
    "    problem=problem, \n",
    "    generation=response.completions[0].completion, \n",
    "    timeout=10,\n",
    ")\n",
    "```\n",
    "\n",
    "### Scoring\n",
    "\n",
    "Use the `score` function to score your solution on the validation set.\n",
    "It expects a function that takes a problem and a client and returns a generation.\n",
    "\n",
    "```python\n",
    "from utilities import score\n",
    "\n",
    "passed_problems, passed_test_cases = score(\n",
    "    generation_func=generate_code, \n",
    "    client=client,\n",
    "    dataset_path=\"./data/val\", \n",
    "    length=50,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T08:23:09.360039Z",
     "start_time": "2024-11-23T08:23:09.356398Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "AA_TOKEN = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjoyNTk4OCwidG9rZW5faWQiOjY0MjB9.UjTE0uGz0u94aKi0MzFr6RJ9eCqEECyxE8bimbpfoyM\"\n",
    "# MODEL = \"llama-3.1-8b-instruct-long-context\"\n",
    "MODEL = \"llama-3.1-70b-instruct-long-context\"\n",
    "\n",
    "if AA_TOKEN is None:\n",
    "    raise ValueError(\"Aleph Alpha Playground token is not set.\")\n",
    "\n",
    "from aleph_alpha_client import Client, CompletionRequest, Prompt\n",
    "from utilities import load_sample, run_test_cases\n",
    "\n",
    "\n",
    "client = Client(AA_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_prompt(problem):\n",
    "    prompt = \"\\nQUESTION:\\n\"\n",
    "    prompt += problem[\"question\"]\n",
    "    prompt += \"\\n\\nSTARTER CODE:\\n\"\n",
    "    prompt += problem[\"starter_code\"]\n",
    "    \n",
    "    # Add Input-Output Examples\n",
    "    prompt += \"\\n\\nInput-Output Examples:\\n\"\n",
    "    for inp, out in zip(problem[\"input_output\"][\"inputs\"], problem[\"input_output\"][\"outputs\"]):\n",
    "        # Assuming inputs and outputs are single-element lists\n",
    "        input_str = inp[0]\n",
    "        output_str = out[0]\n",
    "        prompt += f\"Input: \\\"{input_str}\\\"\\nOutput: {output_str}\\n\\n\"\n",
    "    \n",
    "    # Add output examples\n",
    "    prompt += \"An example of a proper response format:\"\n",
    "    prompt += \"def expression_matter(a, b, c): \\n return max(a*(b+c), a+b*c, (a+b)*c, a*b*c, a+b+c)\"\n",
    "    \n",
    "    # Clear and Explicit Instructions\n",
    "    prompt += \"Write only the executable Python code that completes the function above. Do not include any comments, tests, or additional text.\\n\"\n",
    "    prompt += \"Do not use markdown code blocks.\\n\\n\"\n",
    "    \n",
    "    # Indicate where the code should be inserted\n",
    "    prompt += \"CODE:\\n\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T13:44:44.036322Z",
     "start_time": "2024-11-23T13:44:43.803008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def expression_matter(a, b, c): \n",
      " return max(a*(b+c), a+b*c, (a+b)*c, a*b*c, a+b+c)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def generate_prompt(problem: dict) -> str:\n",
    "    \"\"\"\n",
    "    Generate a prompt for a given problem.\n",
    "    \n",
    "    Args:\n",
    "        problem (dict): A dictionary containing the problem, test cases, and starter code.\n",
    "    Returns:\n",
    "        str: A prompt for the given problem.\n",
    "    \"\"\"\n",
    "\n",
    "    # prompt += '''\\n\\n Example of a proper response format:\n",
    "    # def climb(n):\n",
    "    #     seq = [1]\n",
    "    #     while seq[-1] < n:\n",
    "    #     if seq[-1] * 2 + 1 <= n:\n",
    "    #         seq.append(seq[-1] * 2 + 1)\n",
    "    #     else:\n",
    "    #         seq.append(seq[-1] * 2)\n",
    "    #     return seq if seq[-1] == n else []\\n\\n'''\n",
    "    \n",
    "    prompt = build_prompt(problem)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "def generate_code(problem: dict, client: Client) -> str:\n",
    "    \"\"\"\n",
    "    Implement the generation function.\n",
    "    \n",
    "    Args:\n",
    "        problem (dict): The problem to solve.\n",
    "        \n",
    "    Returns:\n",
    "        str: The generated code.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = generate_prompt(problem=problem)\n",
    "\n",
    "    request = CompletionRequest(\n",
    "        prompt=Prompt.from_text(prompt),\n",
    "        maximum_tokens=250,\n",
    "    )\n",
    "\n",
    "    # API reference for the client:\n",
    "    # https://aleph-alpha-client.readthedocs.io/en/latest/\n",
    "    response = client.complete(request, model=MODEL)\n",
    "    response = response.completions[0].completion\n",
    "    \n",
    "    # Run test cases on the generated code and iterate.\n",
    "    # test_results = run_test_cases(\n",
    "    #    problem=problem, \n",
    "    #    generation=response.completions[0].completion, \n",
    "    #    timeout=10,\n",
    "    # )\n",
    "\n",
    "    # response_string = response.completions[0].completion    \n",
    "    # response_string = response_string.replace(\"'''\", \"\").replace(\"```\", \"\").replace('\"\"\"','').replace('python', '').strip()\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "problem = load_sample(index=0, dataset_path=\"./data/dev\")\n",
    "generated_code = generate_code(problem, client)\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Deletes a JSON file if it exists.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file to be deleted.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"File '{file_path}' has been deleted.\")\n",
    "        else:\n",
    "            print(f\"File '{file_path}' does not exist.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while trying to delete the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File './analysis_results.json' has been deleted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:16<00:11,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to get function error = (<class 'AttributeError'>, AttributeError(\"module 'tmp_sol' has no attribute 'combinationSum3'\"), <traceback object at 0x7fb194c8a900>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:20<00:09,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard input runtime error or time limit exceeded error = 'int' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:23<00:15,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type 0 compilation error = invalid syntax (<string>, line 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [00:24<00:10,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type 0 compilation error = closing parenthesis ')' does not match opening parenthesis '[' (<string>, line 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [00:30<00:03,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type 0 compilation error = invalid syntax (<string>, line 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [00:32<00:03,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type 0 compilation error = unterminated string literal (detected at line 23) (<string>, line 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [00:32<00:01,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type 0 compilation error = '[' was never closed (<string>, line 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [00:33<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard input runtime error or time limit exceeded error = list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:43<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed 74.0% of problems\n",
      "Passed 74.0% of test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utilities import score\n",
    "delete_json_file(\"./analysis_results.json\")\n",
    "passed_problems, passed_test_cases = score(\n",
    "    generation_func=generate_code, \n",
    "    #generation_func=generate_code_syntax_coorected,\n",
    "    client=client,\n",
    "    dataset_path=\"./data/val\", \n",
    "    length=50,\n",
    ")\n",
    "\n",
    "print(f\"Passed {passed_problems*100}% of problems\")\n",
    "print(f\"Passed {passed_test_cases*100}% of test cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def shape_area(n):\n",
      "    return n*n + (n-1)*(n-1)\n"
     ]
    }
   ],
   "source": [
    "problem = load_sample(index=12, dataset_path=\"./data/val\")\n",
    "generated_code = generate_code(problem, client)\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def flatten(*args):\n",
      "    result = []\n",
      "    for arg in args:\n",
      "        if isinstance(arg, list):\n",
      "            result.extend(flatten(*arg))\n",
      "        else:\n",
      "            result.append(arg)\n",
      "    return result\n"
     ]
    }
   ],
   "source": [
    "problem = load_sample(index=43, dataset_path=\"./data/val\")\n",
    "generated_code = generate_code(problem, client)\n",
    "print(generated_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Makeathon_python310_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
