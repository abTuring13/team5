{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchpress Hackathon\n",
    "\n",
    "The challenge comes with a Jupyter notebook for your implementation and various utilities.\n",
    "We provide a development set and a validation set you can use to develop your solution.\n",
    "The development set is for testing your code and consists of 300 problems with a varying number of test cases.\n",
    "You are free to use all data provided with a problem, a sample has the following structure:\n",
    "\n",
    "```python\n",
    "{\n",
    "    # Unique identifier for the problem in the APPS dataset.\n",
    "    \"problem_id\": 4424,\n",
    "    # The problem statement\n",
    "    \"question\": \"Given three integers ...\",\n",
    "    # The expected function name and the input/output examples\n",
    "    # representing test cases.\n",
    "    \"input_output\": {\n",
    "        \"fn_name\": \"expression_matter\",\n",
    "        \"inputs\": [ ... ],\n",
    "        \"outputs\": [ ... ]\n",
    "    },\n",
    "    \"url\": \"https://www.codewars.com/kata/5ae62fcf252e66d44d00008e\",\n",
    "    \"difficulty\": \"introductory\",\n",
    "    # The starter code for the problem.\n",
    "    \"starter_code\": \"def expression_matter(a, b, c):\\n\\t\"\n",
    "}\n",
    "```\n",
    "\n",
    "The validation set is consists of 200 problems, and includes an additional key `test_cases` which is used to score your solution with the provided scoring function.\n",
    "\n",
    "```python\n",
    "{\n",
    "    ...\n",
    "    \"test_cases\": {\n",
    "        \"fn_name\": \"expression_matter\",\n",
    "        \"inputs\": [ ... ],\n",
    "        \"outputs\": [ ... ]\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### Loading Problems\n",
    "\n",
    "Use the `load_sample` function to load a problem from the development or validation set.\n",
    "\n",
    "```python\n",
    "from utilities import load_sample\n",
    "\n",
    "problem = load_sample(index=0, dataset_path=\"./data/dev\")\n",
    "```\n",
    "\n",
    "### Generating Code\n",
    "\n",
    "Use the `aleph_alpha_client` to generate code.\n",
    "Make sure your `AA_TOKEN` is set.\n",
    "\n",
    "```python\n",
    "from aleph_alpha_client import Client, CompletionRequest, Prompt\n",
    "\n",
    "client = Client(AA_TOKEN)\n",
    "\n",
    "request = CompletionRequest(\n",
    "    prompt=Prompt.from_text(\"Your prompt.\"),\n",
    "    maximum_tokens=256,\n",
    ")\n",
    "\n",
    "# API reference for the client:\n",
    "# https://aleph-alpha-client.readthedocs.io/en/latest/\n",
    "response = client.complete(request, model=MODEL)\n",
    "```\n",
    "\n",
    "### Running Tests\n",
    "\n",
    "Use the `run_test_cases` function to run the generated code against the test cases.\n",
    "The function returns a dictionary with the test results, including the expected output, the generated output, a boolean indicating whether the test passed and a traceback in case of an error.\n",
    "\n",
    "```python\n",
    "from utilities import run_test_cases\n",
    "\n",
    "test_results = run_test_cases(\n",
    "    problem=problem, \n",
    "    generation=response.completions[0].completion, \n",
    "    timeout=10,\n",
    ")\n",
    "```\n",
    "\n",
    "### Scoring\n",
    "\n",
    "Use the `score` function to score your solution on the validation set.\n",
    "It expects a function that takes a problem and a client and returns a generation.\n",
    "\n",
    "```python\n",
    "from utilities import score\n",
    "\n",
    "passed_problems, passed_test_cases = score(\n",
    "    generation_func=generate_code, \n",
    "    client=client,\n",
    "    dataset_path=\"./data/val\", \n",
    "    length=50,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T08:23:09.360039Z",
     "start_time": "2024-11-23T08:23:09.356398Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import inspect\n",
    "\n",
    "AA_TOKEN = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjoyNTk4OCwidG9rZW5faWQiOjY0MjB9.UjTE0uGz0u94aKi0MzFr6RJ9eCqEECyxE8bimbpfoyM\"\n",
    "# MODEL = \"llama-3.1-8b-instruct-long-context\"\n",
    "MODEL = \"llama-3.1-70b-instruct-long-context\"\n",
    "\n",
    "if AA_TOKEN is None:\n",
    "    raise ValueError(\"Aleph Alpha Playground token is not set.\")\n",
    "\n",
    "from aleph_alpha_client import Client, CompletionRequest, Prompt\n",
    "from utilities import load_sample, run_test_cases\n",
    "\n",
    "\n",
    "client = Client(AA_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_prompt(problem):\n",
    "    prompt = \"\\nQUESTION:\\n\"\n",
    "    prompt += problem[\"question\"]\n",
    "    prompt += \"\\n\\nSTARTER CODE:\\n\"\n",
    "    prompt += problem[\"starter_code\"]\n",
    "    \n",
    "    # Add Input-Output Examples\n",
    "    prompt += \"\\n\\nInput-Output Examples:\\n\"\n",
    "    for inp, out in zip(problem[\"input_output\"][\"inputs\"], problem[\"input_output\"][\"outputs\"]):\n",
    "        # Assuming inputs and outputs are single-element lists\n",
    "        input_str = inp[0]\n",
    "        output_str = out[0]\n",
    "        prompt += f\"Input: \\\"{input_str}\\\"\\nOutput: {output_str}\\n\\n\"\n",
    "    \n",
    "    # Add output examples\n",
    "    prompt += \"An example of a proper response format:\"\n",
    "    prompt += \"def expression_matter(a, b, c): \\n return max(a*(b+c), a+b*c, (a+b)*c, a*b*c, a+b+c)\"\n",
    "    \n",
    "    # Clear and Explicit Instructions\n",
    "    prompt += \"Write only the executable Python code that completes the function above. Do not include any comments, tests, or additional text.\\n\"\n",
    "    prompt += \"Do not use markdown code blocks.\\n\\n\"\n",
    "    \n",
    "    # Indicate where the code should be inserted\n",
    "    prompt += \"CODE:\\n\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt2(problem) -> str:\n",
    "\n",
    "    prompt = \"<|begin_of_text|>\\n\"\n",
    "    prompt += \"<|start_header_id|>system<|end_header_id|>\\n\"\n",
    "    prompt += \"You are a programming assistant. Generate Python code to complete functions as instructed. Follow these rules:\\n\"\n",
    "    prompt += \"1. Write only the executable Python code that completes the function.\\n\"\n",
    "    prompt += \"2. Do not use markdown or code blocks.\\n\"\n",
    "    prompt += \"3. Do not include any comments, tests, or additional text.\\n\"\n",
    "    prompt += \"<|start_header_id|>user<|end_header_id|>\\n\"\n",
    "    prompt += problem[\"question\"]\n",
    "    prompt += \"\\nWrite only the Python code that completes the function:\\n\"\n",
    "    prompt += \"\\n\\nSTARTER CODE:\\n\"\n",
    "    prompt += problem[\"starter_code\"]\n",
    "    prompt += \"\\n<|start_header_id|>assistant<|end_header_id|>\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_code(problem: dict, client: Client) -> str:\n",
    "    \n",
    "    prompt = generate_prompt2(problem=problem)\n",
    "    request = CompletionRequest(\n",
    "        prompt=Prompt.from_text(prompt),\n",
    "        maximum_tokens=350,\n",
    "    )\n",
    "\n",
    "    # API reference for the client:\n",
    "    # https://aleph-alpha-client.readthedocs.io/en/latest/\n",
    "    response = client.complete(request, model=MODEL)\n",
    "    response = response.completions[0].completion\n",
    "    \n",
    "    # Run test cases on the generated code and iterate.\n",
    "    # test_results = run_test_cases(\n",
    "    #    problem=problem, \n",
    "    #    generation=response.completions[0].completion, \n",
    "    #    timeout=10,\n",
    "    # )\n",
    "\n",
    "    # response_string = response.completions[0].completion    \n",
    "    # response_string = response_string.replace(\"'''\", \"\").replace(\"```\", \"\").replace('\"\"\"','').replace('python', '').strip()\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "def expression_matter(a, b, c):\n",
      "    return max(a * (b + c), a + b * c, (a + b) * c, a + b + c)\n",
      "\n",
      "Function Output: 6\n"
     ]
    }
   ],
   "source": [
    "# Test the generated code\n",
    "\n",
    "problem = load_sample(index=0, dataset_path=\"./data/dev\")\n",
    "generated_code = generate_code(problem, client)\n",
    "print(generated_code + \"\\n\")\n",
    "\n",
    "def test_code_given_str(problem, generated_code, inputs):\n",
    "    namespace = {}\n",
    "    exec(generated_code, namespace)\n",
    "    \n",
    "     # Step 4: Retrieve the function from the namespace\n",
    "    # Assume only one function is defined in the generated code\n",
    "    generated_func = None\n",
    "    for obj in namespace.values():\n",
    "        if callable(obj):\n",
    "            generated_func = obj\n",
    "            break\n",
    "    if generated_func is None:\n",
    "        raise ValueError(\"No callable function found in the generated code.\")\n",
    "    \n",
    "    if generated_func is None:\n",
    "        raise ValueError(\"No callable function found in the generated code.\")\n",
    "    \n",
    "    result = generated_func(*inputs)\n",
    "    print(f\"Function Output: {result}\")\n",
    "\n",
    "inputs = (2, 1, 2)\n",
    "test_code_given_str(problem, generated_code,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Deletes a JSON file if it exists.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file to be deleted.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"File '{file_path}' has been deleted.\")\n",
    "        else:\n",
    "            print(f\"File '{file_path}' does not exist.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while trying to delete the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File './analysis_results.json' has been deleted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:20<01:36,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard input runtime error or time limit exceeded error = combinationSum3() missing 1 required positional argument: 'n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:38<02:10,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type 0 compilation error = 'return' outside function (<string>, line 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [00:47<00:51,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type 0 compilation error = 'return' outside function (<string>, line 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:49<00:49,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard input runtime error or time limit exceeded error = list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [00:51<00:28,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard input runtime error or time limit exceeded error = float division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [01:30<00:15,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard input runtime error or time limit exceeded error = 'R'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:39<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed 69.0% of problems\n",
      "Passed 69.6078431372549% of test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utilities import score\n",
    "delete_json_file(\"./analysis_results.json\")\n",
    "passed_problems, passed_test_cases = score(\n",
    "    generation_func=generate_code, \n",
    "    #generation_func=generate_code_syntax_coorected,\n",
    "    client=client,\n",
    "    dataset_path=\"./data/val\", \n",
    "    length=100,\n",
    ")\n",
    "\n",
    "print(f\"Passed {passed_problems*100}% of problems\")\n",
    "print(f\"Passed {passed_test_cases*100}% of test cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "def shape_area(n):\n",
      "    return n*n + (n-1)*(n-1)\n"
     ]
    }
   ],
   "source": [
    "problem = load_sample(index=12, dataset_path=\"./data/val\")\n",
    "generated_code = generate_code(problem, client)\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "def flatten(*args):\n",
      "    result = []\n",
      "    for arg in args:\n",
      "        if isinstance(arg, list):\n",
      "            result.extend(flatten(*arg))\n",
      "        else:\n",
      "            result.append(arg)\n",
      "    return result\n"
     ]
    }
   ],
   "source": [
    "problem = load_sample(index=43, dataset_path=\"./data/val\")\n",
    "generated_code = generate_code(problem, client)\n",
    "print(generated_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
